{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube Dynamic Scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How the script works for the Dynamic loading of a youtube channels vidoe page.\n",
    "Firstly, the driver is set up, I have used ChromeDriver located on my desktop. Then a youtube page's video channel url is manually chosen. After this, the two methods differ, with the For Loop method looping over an arbitrary number greater than the number of videos that a channel has. Each iteration of a loop scrolls to the bottom of a page using the keys function from Selenium, then the BeautifulSoup import is used to obtain a selected property about an individual video. This property is stored in an array, \"Video_arrray\", and then the page is scrolled again. The loop checks that the number of videos stored in the \"Video_array\" as an element increases for each scroll to the bottom. When the element ceases to increase anymore and the kth value is equal to the kth + 1 value, the bottom of the page has been reached. The while loop method is the same, however, it is not required to know how many videos a channel has prior to running the script and therefore, is superior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For loop method \n",
    "#### (okay but its required to know how many videos are on a channel prior to running the script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Videos_array=([0]) #set a value smaller than the expected number of items you want to scrape from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 288, 288]\n",
      "288\n"
     ]
    }
   ],
   "source": [
    "chromedriver = r\"C:\\Users\\tomna\\OneDrive\\Desktop\\chromedriver\" #fill in the location of your browser driver ie:chromedriver\n",
    "driver=webdriver.Chrome(chromedriver)\n",
    "website=driver.get(\"https://www.youtube.com/user/1veritasium/videos\") #locate the channel you wish to scrape from\n",
    "for i in range (1000): # this should be larger than the number of videos on the page\n",
    "    time.sleep(.5)\n",
    "    html=driver.page_source\n",
    "    time.sleep(.5)\n",
    "    soup=BeautifulSoup(html)\n",
    "    time.sleep(.5)\n",
    "    driver.find_element_by_xpath('//body').send_keys(Keys.CONTROL+Keys.END) #scrolling to the bottom of current page\n",
    "    Videos=soup.find_all('a',class_=\"yt-simple-endpoint style-scope ytd-grid-video-renderer\")#identify an aspect of each video\n",
    "    Videos_array.append(len(Videos)) # store the ammount of videos loaded by scroll into an array\n",
    "    time.sleep(.5)\n",
    "    if Videos_array[i+1]==Videos_array[i]: # if the scroll adds more values to the array then it continues\n",
    "        break                              #if it doesnt then all videos are loaded\n",
    "print(Videos_array)\n",
    "print(len(Videos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While loop method \n",
    "#### ( Superior as prior knowledge isnt required )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Videos_array=([0,0.1]) # set two small values that are less than the initial number of videos loaded on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.1, 30, 60, 90, 120, 150, 180, 210, 240, 270, 288, 288]\n",
      "288\n"
     ]
    }
   ],
   "source": [
    "chromedriver = r\"C:\\Users\\tomna\\OneDrive\\Desktop\\chromedriver\" #fill in the location of your browser driver ie:chromedriver\n",
    "driver=webdriver.Chrome(chromedriver)\n",
    "website=driver.get(\"https://www.youtube.com/user/1veritasium/videos\") #locate the channel you wish to scrape from\n",
    "k=Videos_array[0]\n",
    "while Videos_array[k+1]!=Videos_array[k]: \n",
    "    time.sleep(.5)\n",
    "    html=driver.page_source\n",
    "    time.sleep(.5)\n",
    "    soup=BeautifulSoup(html)\n",
    "    time.sleep(.5)\n",
    "    driver.find_element_by_xpath('//body').send_keys(Keys.CONTROL+Keys.END)\n",
    "    Videos=soup.find_all('a',class_=\"yt-simple-endpoint style-scope ytd-grid-video-renderer\")#identify an aspect of each video\n",
    "    Videos_array.append(len(Videos)) # store the ammount of videos loaded by scroll into an array\n",
    "    time.sleep(.5)\n",
    "    if Videos_array[-1]==Videos_array[-2]: # if the scroll adds more values to the array then it continues\n",
    "        break                              #if it doesnt then all videos are loaded\n",
    "print(Videos_array)\n",
    "print(len(Videos))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
